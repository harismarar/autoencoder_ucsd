# -*- coding: utf-8 -*-
"""anomaly-detection_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NRDhvbmQAE4cjWhQelZEzAIi4E_Vnec3
"""

!pip install --upgrade mxnet
!pip install tifffile
!pip install pillow

from google.colab import drive
drive.mount('/content/drive')

# prompt: unzip a tar.gz to a folder in the path /content/drive/MyDrive/ucsd

!tar -xzvf /content/drive/MyDrive/UCSD_Anomaly_Dataset.tar.gz -C /content/drive/MyDrive/ucsd

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt
import glob
import os
import cv2
import numpy as np

def load_and_preprocess_image_opencv(file_path):
    try:
        # Read the image in grayscale
        img = cv2.imread(file_path.numpy().decode("utf-8"), cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError("Image not loaded; possible bad file")
        # Resize the image
        img = cv2.resize(img, (100, 100))
        # Normalize the image
        img_array = img.astype(np.float32) / 255.0
        # Expand the dimensions to add the channel
        img_array = np.expand_dims(img_array, axis=-1)
        return img_array, img_array
    except Exception as e:
        print(f"Error processing image {file_path}: {e}")
        # Return a zero-filled array to maintain consistency
        return np.zeros((100, 100, 1), dtype=np.float32), np.zeros((100, 100, 1), dtype=np.float32)

def show_batch(image_batch):
    plt.figure(figsize=(10, 10))
    for n in range(min(len(image_batch), 25)):  # Show a maximum of 25 images
        ax = plt.subplot(5, 5, n + 1)
        plt.imshow(image_batch[n].squeeze(), cmap='gray')  # Assuming grayscale images
        plt.axis('off')
    plt.show()

def create_dataset(root_dir, batch_size, validation_split=0.1):
    file_paths = glob.glob(os.path.join(root_dir, 'Train', '*', '*.tif'))
    np.random.shuffle(file_paths)
    split_index = int(len(file_paths) * (1 - validation_split))
    train_paths, val_paths = file_paths[:split_index], file_paths[split_index:]

    def _load_image(file_path):
        image, _ = tf.py_function(load_and_preprocess_image_opencv, [file_path], [tf.float32, tf.float32])
        return image, image  # Autoencoder input and output are the same

    train_dataset = tf.data.Dataset.from_tensor_slices(train_paths)
    train_dataset = train_dataset.map(_load_image, num_parallel_calls=tf.data.AUTOTUNE)
    train_dataset = train_dataset.filter(lambda x, y: tf.reduce_sum(x) > 0)
    train_dataset = train_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)

    val_dataset = tf.data.Dataset.from_tensor_slices(val_paths)
    val_dataset = val_dataset.map(_load_image, num_parallel_calls=tf.data.AUTOTUNE)
    val_dataset = val_dataset.filter(lambda x, y: tf.reduce_sum(x) > 0)
    val_dataset = val_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)

    return train_dataset, val_dataset

# Define input shape
input_shape = (100, 100, 1)  # Modify as needed

# Define batch size and root directory for dataset
batch_size = 32
root_dir = '/content/drive/MyDrive/ucsd/UCSD_Anomaly_Dataset.v1p2/UCSDped1/'

# Create train and validation datasets
train_dataset, val_dataset = create_dataset(root_dir, batch_size)

# Debugging: Show first batch from train and val datasets
for images, _ in train_dataset.take(1):
    print("Training Batch:")
    show_batch(images.numpy())

for images, _ in val_dataset.take(1):
    print("Validation Batch:")
    show_batch(images.numpy())

# Define input shape
input_shape = (100, 100, 1)  # Modify as needed

# Define batch size and root directory for dataset
batch_size = 32
root_dir = '/content/drive/MyDrive/ucsd/UCSD_Anomaly_Dataset.v1p2/UCSDped1/'

# Create train and validation datasets
train_dataset, val_dataset = create_dataset(root_dir, batch_size)

# Debugging: Show first batch from train and val datasets
for images, _ in train_dataset.take(1):
    print("Training Batch:")
    show_batch(images.numpy())

for images, _ in val_dataset.take(1):
    print("Validation Batch:")
    show_batch(images.numpy())

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam
import glob
import os
import cv2
import numpy as np


def build_revised_autoencoder(input_shape):
    input_img = Input(shape=input_shape)

    # Encoder
    x = Conv2D(32, (3, 3), padding='same')(input_img)
    x = Activation('relu')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)

    x = Conv2D(32, (3, 3), padding='same')(x)
    x = Activation('relu')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)

    # Decoder
    x = Conv2D(32, (3, 3), padding='same')(x)
    x = Activation('relu')(x)
    x = UpSampling2D((2, 2))(x)

    x = Conv2D(32, (3, 3), padding='same')(x)
    x = Activation('relu')(x)
    x = UpSampling2D((2, 2))(x)

    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)

    # Autoencoder Model
    autoencoder = Model(input_img, decoded)
    autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

    return autoencoder

# Define input shape
input_shape = (100, 100, 1)  # Modify as needed

# Define batch size and root directory for dataset
batch_size = 32
root_dir = '/content/drive/MyDrive/ucsd/UCSD_Anomaly_Dataset.v1p2/UCSDped1/'

# Create train and validation datasets
train_dataset, val_dataset = create_dataset(root_dir, batch_size)

# Build and compile the autoencoder
autoencoder = build_revised_autoencoder(input_shape)

# Define the callbacks
callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ModelCheckpoint(filepath='best_autoencoder_model.h5', monitor='val_loss', save_best_only=True)
]

# Train the model with callbacks for early stopping and model checkpointing
history = autoencoder.fit(
    train_dataset,
    validation_data=val_dataset,
    epochs=10,
    callbacks=callbacks
)

# Save the trained model
autoencoder.save("/content/drive/MyDrive/ucsd/autoencoder_model_2.h5")

# prompt: print the content of the foldetr in the path  /content/drive/MyDrive/ucsd/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test

import os

# Path to the directory
directory_path = "/content/drive/MyDrive/ucsd/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test"

# Get the list of files and directories in the directory
files_and_directories = os.listdir(directory_path)

# Print the contents of the directory
for file_or_directory in files_and_directories:
  print(file_or_directory)

def load_and_preprocess_image_opencv(file_path):
    try:
        # Read the image in grayscale
        img = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            raise ValueError("Image not loaded; possible bad file")
        # Resize the image
        img = cv2.resize(img, (100, 100))
        # Normalize the image
        img_array = img.astype(np.float32) / 255.0
        # Expand the dimensions to add the channel
        img_array = np.expand_dims(img_array, axis=-1)
        return img_array, img_array
    except Exception as e:
        print(f"Error processing image {file_path}: {e}")
        # Return a zero-filled array to maintain consistency
        return np.zeros((100, 100, 1), dtype=np.float32), np.zeros((100, 100, 1), dtype=np.float32)

#test dataset load
def create_dataset_test(root_dir, batch_size):
    file_paths = glob.glob(os.path.join(root_dir, 'Test', '*', '*.tif'))
    dataset = tf.data.Dataset.from_tensor_slices(file_paths)

    def _load_image(file_path):
        file_path = file_path.numpy().decode("utf-8")  # Decode from tensor to string
        image, _ = load_and_preprocess_image_opencv(file_path)
        return tf.convert_to_tensor(image, dtype=tf.float32), tf.convert_to_tensor(image, dtype=tf.float32)

    def load_image_wrapper(file_path):
        # Use tf.py_function to wrap _load_image function
        return tf.py_function(_load_image, [file_path], [tf.float32, tf.float32])

    dataset = dataset.map(load_image_wrapper, num_parallel_calls=tf.data.AUTOTUNE)
    dataset = dataset.filter(lambda x, y: tf.reduce_sum(x) > 0)  # Optionally filter out all-zero images
    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset

# Note: Adjust `root_dir` to your correct directory path
batch_size = 32
root_dir = '/content/drive/MyDrive/ucsd/UCSD_Anomaly_Dataset.v1p2/UCSDped1/'
test_dataset = create_dataset_test(root_dir, batch_size)

for images, _ in test_dataset.take(1):
    # Your existing code to visualize the batch
    show_batch(images.numpy())

import tensorflow as tf
import matplotlib.pyplot as plt

# Load the saved autoencoder model
autoencoder = tf.keras.models.load_model('/content/drive/MyDrive/ucsd/autoencoder_model.h5')

def visualize_reconstruction(test_dataset, autoencoder, num_images=10):
    plt.figure(figsize=(20, 4))
    for images, _ in test_dataset.take(1):
        predictions = autoencoder.predict(images)
        for i in range(num_images):
            # Display original images
            ax = plt.subplot(2, num_images, i + 1)
            plt.imshow(images[i].numpy().squeeze(), cmap='gray')
            plt.title("Original")
            plt.axis('off')

            # Display reconstructed images
            ax = plt.subplot(2, num_images, i + 1 + num_images)
            plt.imshow(predictions[i].squeeze(), cmap='gray')
            plt.title("Reconstructed")
            plt.axis('off')
    plt.show()

# Assuming you have a test_dataset ready
# Modify the code below to load your test dataset
# test_dataset = ...

visualize_reconstruction(test_dataset, autoencoder)

reconstruction_errors = []
for images, _ in test_dataset:
    predictions = autoencoder.predict(images)
    reconstruction_errors.append(np.mean(np.abs(images.numpy() - predictions), axis=(1, 2, 3)))

mean_error = np.mean(reconstruction_errors)
std_error = np.std(reconstruction_errors)

# Set a threshold as mean + 2*std of reconstruction errors
threshold = mean_error + 2*std_error
print("Threshold for anomaly detection:", threshold)

reconstruction_errors = []
for images, _ in test_dataset:
    predictions = autoencoder.predict(images)
    errors = np.mean(np.abs(images.numpy() - predictions), axis=(1, 2, 3))
    reconstruction_errors.extend(errors)  # Use extend to add scalar values

mean_error = np.mean(reconstruction_errors)
std_error = np.std(reconstruction_errors)

# Set a threshold as mean + 2*std of reconstruction errors
threshold = mean_error + 2*std_error
print("Threshold for anomaly detection:", threshold)

def visualize_anomalies(dataset, autoencoder, threshold):
    plt.figure(figsize=(20, 4))
    num_anomalies = 0
    for images, _ in dataset:
        predictions = autoencoder.predict(images)
        errors = np.mean(np.abs(images.numpy() - predictions), axis=(1, 2, 3))

        for i, error in enumerate(errors):
            if error > threshold:
                if num_anomalies >= 10:  # Display only the first 10 anomalies
                    return
                num_anomalies += 1

                # Display anomalous images
                ax = plt.subplot(2, 10, num_anomalies)
                plt.imshow(images[i].numpy().squeeze(), cmap='gray')
                plt.title(f"Error: {error:.2f}")
                plt.axis('off')

visualize_anomalies(test_dataset, autoencoder, threshold)

import tensorflow as tf
import numpy as np
import cv2
import os
import IPython.display as display
from PIL import Image
import io

# Function to preprocess the images
def preprocess_image(frame):
    # Resize and normalize the image
    frame = cv2.resize(frame, (100, 100))
    frame = frame / 255.0
    frame = np.expand_dims(frame, axis=-1)  # Add channel dimension if needed
    return frame

# Function to display a frame
def display_frame(frame, format='jpeg'):
    f = io.BytesIO()
    img = Image.fromarray(frame)
    img.save(f, format)
    display.display(display.Image(data=f.getvalue()))

# Load your trained autoencoder model
#autoencoder = tf.keras.models.load_model('/path/to/your_model.h5')

# Set a threshold for anomaly detection
threshold = 0.01  # Adjust based on your model and validation set

# Directory containing the video frames
frame_dir = '/content/drive/MyDrive/ucsd/UCSD_Anomaly_Dataset.v1p2/UCSDped1/Test/Test003'

# Process and display each frame
for frame_name in sorted(os.listdir(frame_dir)):
    if frame_name.endswith('.tif'):
        frame_path = os.path.join(frame_dir, frame_name)
        frame = cv2.imread(frame_path, cv2.IMREAD_GRAYSCALE)
        preprocessed_frame = preprocess_image(frame)

        # Model prediction
        reconstructed_frame = autoencoder.predict(np.expand_dims(preprocessed_frame, axis=0))[0]

        # Calculate error
        mse = np.mean(np.power(preprocessed_frame - reconstructed_frame, 2))

        # Mark frame as an anomaly with a red circle if mse exceeds threshold
        if mse > threshold:
            frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)  # Convert grayscale to BGR color space
            center_coords = (frame.shape[1] // 2, frame.shape[0] // 2)
            cv2.circle(frame, center_coords, 20, (0, 0, 255), 2)  # Draw red circle

        # Display the frame with potential anomaly highlighted
        display_frame(frame)
        display.clear_output(wait=True)  # Clear the output to display the next frame

import numpy as np
import tensorflow as tf
from IPython.display import Image, display
import imageio
from io import BytesIO

# Set your anomaly detection threshold
anomaly_threshold = 0.04

def create_and_display_anomaly_gif(autoencoder, test_dataset, anomaly_threshold):
    images_for_gif = []  # List to hold the images for the GIF
    for batch in test_dataset.take(5):  # Take just the first batch from the dataset
        test_images = batch[0].numpy()  # Get the images from the batch
        reconstructed_images = autoencoder.predict(test_images)  # Get the reconstructed images from the autoencoder

        # Calculate the reconstruction error
        reconstruction_errors = np.abs(test_images - reconstructed_images)

        for i in range(test_images.shape[0]):
            # Find anomalies (where the error is above the threshold)
            anomalies = reconstruction_errors[i] > anomaly_threshold
            anomalies = anomalies.squeeze()  # Ensure anomalies is 2D

            # Create an RGB image for the anomalies
            anomaly_image = np.zeros((test_images[i].shape[0], test_images[i].shape[1], 3), dtype=np.uint8)
            anomaly_image[anomalies, :] = [255, 0, 0]  # Red channel for anomalies

            # Ensure all images have three channels
            original_rgb = np.squeeze(np.stack((test_images[i],) * 3, axis=-1))
            reconstructed_rgb = np.squeeze(np.stack((reconstructed_images[i],) * 3, axis=-1))

            # Normalize and convert images to uint8
            original_uint8 = (original_rgb * 255).astype(np.uint8)
            reconstructed_uint8 = (reconstructed_rgb * 255).astype(np.uint8)

            # Overlay anomalies on the original image
            original_with_anomalies = original_uint8.copy()
            original_with_anomalies[anomalies, :] = [255, 0, 0]

            # Combine the original, reconstructed, and anomaly images
            combined_image = np.hstack((original_uint8, reconstructed_uint8, original_with_anomalies))

            # Append to the list of images for GIF
            images_for_gif.append(combined_image)

        # Convert the list of images to a byte buffer for display in the notebook
        gif_bytes = BytesIO()
        imageio.mimsave(gif_bytes, images_for_gif, fps=2, format='gif')
        display(Image(data=gif_bytes.getvalue(), format='gif'))

# Call the function with your model, test dataset, and chosen threshold
create_and_display_anomaly_gif(autoencoder, train_dataset, anomaly_threshold)

import numpy as np
import tensorflow as tf
from IPython.display import Image, display
import imageio
from io import BytesIO

# Define the function to create and display the GIF
def create_and_display_anomaly_gif(model, dataset, threshold):
    # Initialize the buffer for the GIF
    gif_buffer = BytesIO()

    # Process the dataset
    for batch in dataset.take(1):  # Taking only the first batch
        input_batch = batch[0]  # Assuming the first element is the input

        # Predict the reconstructed images
        reconstructed_images = model.predict(input_batch)

        # Calculate the reconstruction errors
        errors = np.abs(input_batch - reconstructed_images)

        # Determine the threshold for anomalies
        anomalies = errors > threshold

        # Prepare the images for the GIF
        frames = []
        for i in range(input_batch.shape[0]):
            # Get the individual frames
            original_frame = input_batch[i].numpy().squeeze()
            reconstructed_frame = reconstructed_images[i].squeeze()
            error_frame = errors[i].squeeze()

            # Identify the anomalies and mark them in red
            anomalies_current_frame = anomalies[i].squeeze()
            anomaly_frame = np.zeros_like(original_frame)
            anomaly_frame[anomalies_current_frame] = 255  # Mark anomalies in red

            # Stack the frames horizontally
            combined_frame = np.hstack((original_frame, reconstructed_frame, error_frame, anomaly_frame))
            frames.append(combined_frame)

        # Save the frames as a GIF
        imageio.mimsave(gif_buffer, np.array(frames).astype(np.uint8), format='GIF', fps=5)

    # Display the GIF
    display(Image(data=gif_buffer.getvalue(), format='gif', embed=True))

# Now call the function with your autoencoder model and the test dataset
create_and_display_anomaly_gif(autoencoder, test_dataset, threshold=0.1)

